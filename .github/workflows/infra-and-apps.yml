name: Infra + EKS Apps

on:
  push:
    branches: [ main ]
    paths:
      - "infra/**"
      - "eks-apps/**"
      - ".github/workflows/infra-and-apps.yml"
  workflow_dispatch:
    inputs:
      tf_action:
        description: "Terraform action"
        required: true
        default: "apply"
        type: choice
        options: [ "apply", "plan" ]
      environment:
        description: "Deployment environment (maps to TF var files/workspaces)"
        required: true
        default: "dev"
        type: choice
        options: [ "dev", "stage", "prod" ]

permissions:
  id-token: write   # needed for AWS OIDC
  contents: read

env:
  AWS_REGION: ap-south-1             # change to your region
  TF_WORKING_DIR: infra              # Terraform directory
  APPS_DIR: eks-apps                 # Your shell scripts
  TF_VAR_file_prefix: env            # e.g., infra/env.dev.tfvars
  # If you use workspaces instead of tfvars, you can switch logic below.

jobs:
  terraform:
    name: Terraform (${{ inputs.environment || 'dev' }})
    runs-on: ubuntu-latest

    outputs:
      cluster_name: ${{ steps.capture_out.outputs.cluster_name }}
      cluster_sg: ${{ steps.capture_out.outputs.cluster_sg }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}   # <- set this secret
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.5

      - name: Terraform Init
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          terraform init \
            -input=false

      # If you prefer workspaces, uncomment:
      # - name: Select/Create workspace
      #   working-directory: ${{ env.TF_WORKING_DIR }}
      #   run: |
      #     terraform workspace select ${{ inputs.environment || 'dev' }} || \
      #     terraform workspace new ${{ inputs.environment || 'dev' }}

      - name: Terraform Validate
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: terraform validate

      - name: Terraform Plan
        if: ${{ github.event_name == 'workflow_dispatch' && inputs.tf_action == 'plan' }}
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          terraform plan \
            -var-file="${{ env.TF_VAR_file_prefix }}.${{ inputs.environment || 'dev' }}.tfvars" \
            -input=false

      - name: Terraform Apply (auto-approve)
        if: ${{ github.event_name != 'workflow_dispatch' || inputs.tf_action == 'apply' }}
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          terraform apply -auto-approve \
            -var-file="${{ env.TF_VAR_file_prefix }}.${{ inputs.environment || 'dev' }}.tfvars" \
            -input=false

      - name: Capture outputs for EKS
        id: capture_out
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          # Make sure your Terraform defines these outputs:
          # output "cluster_name" { value = aws_eks_cluster.this.name }
          # (Optionally) output "cluster_sg" { value = aws_eks_cluster.this.vpc_config[0].cluster_security_group_id }
          echo "cluster_name=$(terraform output -raw cluster_name)" >> $GITHUB_OUTPUT
          # If you don't have this output, remove it:
          if terraform output -json | jq -er '.cluster_sg' >/dev/null 2>&1; then
            echo "cluster_sg=$(terraform output -raw cluster_sg)" >> $GITHUB_OUTPUT
          fi

  deploy-apps:
    name: Deploy EKS Apps
    needs: terraform
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment || 'dev' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl & helm
        run: |
          sudo curl -sSL -o /usr/local/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
          sudo chmod +x /usr/local/bin/kubectl
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

      - name: Configure kubeconfig for EKS
        run: |
          aws eks update-kubeconfig \
            --name "${{ needs.terraform.outputs.cluster_name }}" \
            --region "${{ env.AWS_REGION }}"

      - name: Wait for nodes ready (up to 10m)
        run: |
          echo "Waiting for EKS worker nodes to become Ready..."
          for i in {1..60}; do
            READY=$(kubectl get nodes --no-headers 2>/dev/null | awk '{print $2}' | grep -c "Ready" || true)
            if [ "$READY" -ge 1 ]; then
              kubectl get nodes -o wide
              exit 0
            fi
            sleep 10
          done
          echo "Nodes not ready in time"; kubectl get nodes -o wide || true; exit 1

      - name: Make deploy script executable
        working-directory: ${{ env.APPS_DIR }}
        run: chmod +x deploy-apps.sh

      - name: Run deploy script
        working-directory: ${{ env.APPS_DIR }}
        env:
          # If your script relies on any env vars, export them here:
          # CLUSTER_ISSUER: letsencrypt-prod
          # HOST_GRAFANA: grafana.ushasree.xyz
          # HOST_ARGOCD: argocd.ushasree.xyz
          # etc.
          AWS_REGION: ${{ env.AWS_REGION }}
        run: ./deploy-apps.sh

      # Optional: surface some health info in logs
      - name: Show certificates & ingresses
        run: |
          kubectl get certificate -A
          kubectl get ingress -A
