name: Infra + EKS Deploy (One Flow)

on:
  push:
    branches: [ main ]
    paths:
      - 'Infra/**'
      - 'eks-apps/**'
      - '.github/workflows/infra-and-deploy.yml'
  workflow_dispatch:

permissions:
  id-token: write   # OIDC
  contents: read

env:
  AWS_REGION: ${{ vars.AWS_REGION || 'ap-south-1' }}
  EKS_CLUSTER_NAME: ushasreestores-eks
  TF_IN_AUTOMATION: true
  TF_INPUT: 0
  TF_STATE_KEY: infra/terraform.tfstate
  TF_STATE_BUCKET: ${{ vars.TF_STATE_BUCKET || 'ushasreestores-s3-tfstate' }}
  TF_STATE_DDB: ${{ vars.TF_STATE_DYNAMODB_TABLE || 'ushasreestores-s3-tflock' }}

jobs:
  infra_and_deploy:
    runs-on: ubuntu-latest
    concurrency:
      group: infra-and-deploy-${{ github.ref_name }}
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.5

      # ---------- Phase 0: optional fmt (non-blocking) ----------
      - name: Terraform fmt (non-blocking)
        working-directory: Infra
        run: |
          set +e
          terraform fmt -check -recursive
          status=$?
          if [ $status -eq 3 ]; then
            echo "::warning::Terraform files need formatting. Run 'terraform fmt -recursive' locally."
            terraform fmt -diff -recursive || true
            exit 0
          fi
          exit $status

      # ---------- Phase 1: Bootstrap backend resources with local backend ----------
      - name: Init (LOCAL backend, no S3 yet)
        working-directory: Infra
        run: terraform init -reconfigure -backend=false

      - name: Create S3 bucket & DynamoDB lock (bootstrap)
        working-directory: Infra
        run: |
          set -euo pipefail
          # Apply only the backend infra resources
          terraform apply -auto-approve \
            -target=aws_s3_bucket.tfstate \
            -target=aws_s3_bucket_versioning.tfstate \
            -target=aws_s3_bucket_server_side_encryption_configuration.tfstate \
            -target=aws_dynamodb_table.tf_lock

      # ---------- Phase 2: Re-init using S3 backend (now exists) ----------
      - name: Re-init to S3 backend (reconfigure + migrate)
        working-directory: Infra
        run: |
          set -euo pipefail
          terraform init -reconfigure \
            -backend-config="bucket=${{ env.TF_STATE_BUCKET }}" \
            -backend-config="key=${{ env.TF_STATE_KEY }}" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ env.TF_STATE_DDB }}" \
            -backend-config="encrypt=true"

      - name: Validate
        working-directory: Infra
        run: terraform validate

      # ---------- Phase 3: Apply full infra (EKS/VPC/RDS etc.) ----------
      - name: Terraform apply (full)
        working-directory: Infra
        run: terraform apply -auto-approve

      - name: Wait for EKS ACTIVE
        run: |
          set -euo pipefail
          aws eks wait cluster-active --name "$EKS_CLUSTER_NAME"

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Setup Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      - name: Update kubeconfig & quick check
        run: |
          set -euo pipefail
          aws eks update-kubeconfig --name "$EKS_CLUSTER_NAME" --region "$AWS_REGION"
          kubectl version --short || true
          kubectl get nodes -o wide

      - name: Make scripts executable
        run: |
          chmod +x eks-apps/deployapps.sh || true
          chmod +x eks-apps/appsdeploy.sh || true
          chmod +x eks-apps/argocd/argocd.sh || true
          chmod +x eks-apps/nginx-ingress/*.sh || true
          chmod +x eks-apps/monitoring/monitoring.sh || true

      - name: Deploy apps (deployapps.sh)
        run: |
          set -euo pipefail
          ./eks-apps/deployapps.sh

      - name: Post-deploy sanity
        run: |
          kubectl get ns
          kubectl get pods -A
          kubectl get svc -A
          kubectl get ingress -A

      - name: Collect diagnostics on failure
        if: failure()
        run: |
          mkdir -p diag
          kubectl get nodes -o wide > diag/nodes.txt || true
          kubectl get pods -A -o wide > diag/pods.txt || true
          kubectl describe pods -A > diag/pods_describe.txt || true
          kubectl get events -A --sort-by=.lastTimestamp > diag/events.txt || true
          kubectl get ing -A -o yaml > diag/ingresses.yaml || true
          kubectl get svc -A -o yaml > diag/services.yaml || true

      - name: Upload diagnostics
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: k8s-diagnostics
          path: diag/
