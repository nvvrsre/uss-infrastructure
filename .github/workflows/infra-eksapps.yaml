name: Infra + EKS Deploy (OIDC, One Flow)

on:
  push:
    branches: [ main ]
    paths:
      - 'Infra/**'
      - 'eks-apps/**'
      - '.github/workflows/infra-and-deploy.yml'
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: ${{ secrets.AWS_REGION || vars.AWS_REGION || 'ap-south-1' }}
  EKS_CLUSTER_NAME: ${{ secrets.EKS_CLUSTER_NAME || 'ushasreestores-eks' }}
  TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET || vars.TF_STATE_BUCKET || 'ushasreestores-s3-tfstate' }}
  TF_STATE_DYNAMODB_TABLE: ${{ secrets.TF_STATE_DYNAMODB_TABLE || vars.TF_STATE_DYNAMODB_TABLE || 'ushasreestores-s3-tflock' }}
  TF_STATE_KEY: ${{ secrets.TF_STATE_KEY || 'infra/terraform.tfstate' }}
  TF_IN_AUTOMATION: true
  TF_INPUT: 0

jobs:
  infra_and_deploy:
    runs-on: ubuntu-latest
    concurrency:
      group: infra-and-deploy-${{ github.ref_name }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Who am I (sanity)
        run: aws sts get-caller-identity

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.5

      # ---------- Phase 1: Bootstrap backend (only if missing) ----------
      - name: Check backend resources
        id: backend_exists
        run: |
          set -e
          need_bootstrap=0
          if ! aws s3api head-bucket --bucket "${TF_STATE_BUCKET}" 2>/dev/null; then
            need_bootstrap=1
          fi
          if ! aws dynamodb describe-table --table-name "${TF_STATE_DYNAMODB_TABLE}" >/dev/null 2>&1; then
            need_bootstrap=1
          fi
          echo "need_bootstrap=${need_bootstrap}" >> "$GITHUB_OUTPUT"

      - name: Terraform init (LOCAL, no backend)
        if: steps.backend_exists.outputs.need_bootstrap == '1'
        run: terraform -chdir=Infra init -reconfigure -backend=false

      - name: Create S3 & DynamoDB (bootstrap)
        if: steps.backend_exists.outputs.need_bootstrap == '1'
        run: |
          terraform -chdir=Infra apply -auto-approve \
            -target=aws_s3_bucket.tfstate \
            -target=aws_s3_bucket_versioning.tfstate \
            -target=aws_s3_bucket_server_side_encryption_configuration.tfstate \
            -target=aws_dynamodb_table.tf_lock

      # ---------- Phase 2: Re-init to S3 backend ----------
      - name: Terraform init (S3 backend, reconfigure)
        run: |
          terraform -chdir=Infra init -reconfigure \
            -backend-config="bucket=${TF_STATE_BUCKET}" \
            -backend-config="key=${TF_STATE_KEY}" \
            -backend-config="region=${AWS_REGION}" \
            -backend-config="dynamodb_table=${TF_STATE_DYNAMODB_TABLE}" \
            -backend-config="encrypt=true"

      - name: Terraform validate
        run: terraform -chdir=Infra validate

      - name: Terraform plan
        run: terraform -chdir=Infra plan -input=false -out=tfplan.bin

      - name: Terraform apply
        run: terraform -chdir=Infra apply -input=false -auto-approve tfplan.bin

      # ---------- Phase 3: EKS deploy ----------
      - name: Wait for EKS ACTIVE
        run: aws eks wait cluster-active --name "$EKS_CLUSTER_NAME"

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Setup Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      - name: Update kubeconfig & quick check
        run: |
          aws eks update-kubeconfig --name "$EKS_CLUSTER_NAME" --region "$AWS_REGION"
          kubectl version --client=true -o yaml || true
          kubectl get nodes -o wide

      # ---- Ensure your local IAM user has cluster-admin (idempotent) ----
      - name: Show aws-auth BEFORE
        run: |
          set -e
          kubectl -n kube-system get configmap aws-auth -o yaml || true

      - name: Install eksctl (Linux runner)
        run: |
          set -e
          curl -sSL https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_Linux_amd64.tar.gz -o eksctl.tar.gz
          tar -xzf eksctl.tar.gz
          sudo mv eksctl /usr/local/bin
          eksctl version || true

      - name: Ensure Vishnu is mapped in aws-auth
        run: |
          set -euo pipefail
          if ! kubectl -n kube-system get configmap aws-auth -o yaml | grep -q "arn:aws:iam::182462214834:user/Vishnuvardhan"; then
            eksctl create iamidentitymapping \
              --region "${AWS_REGION}" \
              --cluster "${EKS_CLUSTER_NAME}" \
              --arn arn:aws:iam::182462214834:user/Vishnuvardhan \
              --username vishnu \
              --group system:masters
            echo "✅ Added mapping to aws-auth"
          else
            echo "✅ Mapping already present in aws-auth"
          fi

      - name: Show aws-auth AFTER
        run: |
          set -e
          kubectl -n kube-system get configmap aws-auth -o yaml

      - name: Make scripts executable
        run: |
          chmod +x eks-apps/deployapps.sh || true
          chmod +x eks-apps/appsdeploy.sh || true
          chmod +x eks-apps/argocd/argocd.sh || true
          chmod +x eks-apps/nginx-ingress/*.sh || true
          chmod +x eks-apps/monitoring/monitoring.sh || true

      - name: Deploy apps (deployapps.sh)
        run: ./eks-apps/deployapps.sh

      - name: Post-deploy sanity
        run: |
          kubectl get ns
          kubectl get pods -A
          kubectl get svc -A
          kubectl get ingress -A

      - name: Collect diagnostics on failure
        if: failure()
        run: |
          mkdir -p diag
          kubectl get nodes -o wide > diag/nodes.txt || true
          kubectl get pods -A -o wide > diag/pods.txt || true
          kubectl describe pods -A > diag/pods_describe.txt || true
          kubectl get events -A --sort-by=.lastTimestamp > diag/events.txt || true
          kubectl get ing -A -o yaml > diag/ingresses.yaml || true
          kubectl get svc -A -o yaml > diag/services.yaml || true

      - name: Upload diagnostics
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: k8s-diagnostics
          path: diag/
